{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect Three \n",
    "\n",
    "The primary description of this coursework is available on the CM20252 Moodle page. This is the Jupyter notebook you must complete and submit to receive marks. This notebook adds additional detail to the coursework specification but does not repeat the information that has already been provided there. \n",
    "\n",
    "You must follow all instructions given in this notebook precisely.\n",
    "\n",
    "Restart the kernel and run all cells before submitting the notebook. This will guarantee that we will be able to run your code for testing. Remember to save your work regularly.\n",
    "\n",
    "__You will develop players for Connect-Three on a grid that is 5 columns wide and 3 rows high. An example is shown below showing a win for Player Red.__\n",
    "\n",
    "<img src=\"images/connect3.png\" style=\"width: 200px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries\n",
    "\n",
    "For your reference, below is a visual depiction of the agent-environment interface in reinforcment learning. The interaction of the agent with its environments starts at decision stage $t=0$ with the observation of the current state $s_0$. (Notice that there is no reward at this initial stage.) The agent then chooses an action to execute at decision stage $t=1$. The environment responds by changing its state to $s_1$ and returning the numerical reward signal $r_1$. \n",
    "\n",
    "<img src=\"images/agent-environment.png\" style=\"width: 500px;\"/>\n",
    "\n",
    "<br><br><br>\n",
    "\n",
    "Below, we provide some code that will be useful for implementing parts of this interface. You are not obligated to use this code; please feel free to develop your own code from scratch. \n",
    "\n",
    "### Code details\n",
    "\n",
    "We provide a `Connect` class that you can use to simulate Connect-Three games. The following cells in this section will walk you through the basic usage of this class by playing a couple of games.\n",
    "\n",
    "We import the `connect` module and create a Connect-Three environmnet called `env`. The constructor method has one argument called `verbose`. If `verbose=True`, the `Connect` object will regularly print the progress of the game. This is useful for getting to know the provided code, debugging your code, or if you just want to play around. You will want to set `verbose=False` when you run hundreds of episodes to complete the marked exercises.\n",
    "\n",
    "This `Connect` environment uses the strings `'o'` and `'x'` instead of different disk colors in order to distuingish between the two players.\n",
    "\n",
    "Before we start a game, we should call the `reset()` method. This method cleans the board and resets other state variables. The `first_player` argument can be specified (`'o'` or `'x'`) to deterministically choose the starting player. It defaults to `\"random\"`, in which case each player starts the game with probability of $\\frac{1}{2}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import connect\n",
    "env = connect.Connect(verbose=True)\n",
    "env.reset(first_player='o')\n",
    "x=env.grid\n",
    "print(x.dtype)\n",
    "print(x[0])\n",
    "\n",
    "conversion_vector = 3 ** np.arange(5)\n",
    "test = int(x[0].dot(conversion_vector))\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can interact with the environment using the `act()` method. This method takes an `action` as input and computes the response of the environment. An action is defined as the column index that a disk is dropped into."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.act(action=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `act()` method inserts a disk into the specified column. \n",
    "\n",
    "If we want to change the player on move, we can do so by using the `change_turn()` method. We can check whose turn it is by accessing the `.player_at_turn` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Current player at turn:\", env.player_at_turn)\n",
    "env.change_turn()\n",
    "print(\"Current player at turn:\", env.player_at_turn)\n",
    "\n",
    "# Drop another disk into the same centre column.\n",
    "env.act(action=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we set `verbose=True`, the grid is printed each time we call the `act()` method. This grid is stored as a two-dimensional numpy array in the connect class and you can easily access by calling..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_grid = env.grid\n",
    "print(current_grid)\n",
    "\n",
    "print(tuple(env.grid.flatten()))\n",
    "# Notice that the grid now appears to be \"upside down\" because numpy arrays are printed from \"top to bottom\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make another move.\n",
    "env.change_turn()\n",
    "env.act(action=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we make another move with `act(action=2)`, the environment will throw an error because that column is already filled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell should throw an error!\n",
    "env.change_turn()\n",
    "env.act(action=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attribute `.available_actions` contains a numpy array of all not yet filled columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(env.available_actions)\n",
    "# Column index '2' is missing because this column is already filled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Connect` class contains a method called `was_winning_move()` that checks whether the last move won the game (returns `True`) or not (returns `False`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obviously the game has not yet been won by any player.\n",
    "print(\"Winning move?\", env.was_winning_move()) \n",
    "\n",
    "# Make some moves\n",
    "env.act(action=3)\n",
    "env.change_turn()\n",
    "env.act(action=1)\n",
    "env.change_turn()\n",
    "env.act(action=3)\n",
    "env.change_turn()\n",
    "env.act(action=0)\n",
    "\n",
    "# Check again whether a player has won the game.\n",
    "print(\"Winning move?\", env.was_winning_move()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the `Connect` class contains a method called `grid_is_full()` that checks whether the grid still contains empty slots. You can use this method to check whether the game is a draw.\n",
    "\n",
    "Feel free to modify existing or add new methods to the `Connect` class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Q-learning\n",
    "\n",
    "Your opponent is always the first player. Your agent is always the second player.\n",
    "\n",
    "For your reference, the pseudo-code for Q-learning is reproduced below from the textbook (Reinforcement Learning, Sutton & Barto, 1998, Section 6.5).\n",
    "<img src=\"images/q_learning.png\" style=\"width: 600px;\"/>\n",
    "\n",
    "Prepare a **learning curve** following the directions below. We refer to this as Plot 1.\n",
    "\n",
    "After $n$ steps of interaction with the environment, play $m$ games with the current policy of the agent (without modifying the policy). Think of this as interrupting the agent for a period of time to test how well it has learned so far. Your plot should show the total score obtained in these $m$ games as a function of $n, 2n, 3n, … kn$. The choices of $n$ and $k$ are up to you. They should be reasonable values that demonstrate the efficiency of the learning and how well the agent learns to play the game eventually. Use $m=10$. \n",
    "\n",
    "This plot should show the mean performance of $a$ agents, not the performance of a single agent. Because of the stochasticity in the environment, you will obtain two different learning curves from two different agents even though they are using exactly the same algorithm. We suggest setting $a$ to 30 or higher.\n",
    "\n",
    "Present a single mean learning curve with your choice of parameters $\\epsilon$ and $\\alpha$. The plot should also show (as a baseline) the mean performance of a random agent that does not learn but chooses actions uniformly randomly from among the legal actions. Label this line “Random Agent”. \n",
    "\n",
    "Please include this plot as a static figure in the appropriate cell below. You can look at the source code of this markdown cell to find out how to embed figures using html or you can use drag & drop. If you link to locally stored images, make sure to include those in your submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import connect\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class RandomAgent():\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def choose_action(self, available_actions, state):\n",
    "        return random.choice(available_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QLearningAgent():\n",
    "    \n",
    "    def __init__(self, alpha=0.1, gamma=1.0, epsilon=0.05):\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.Q = {}\n",
    "    \n",
    "    def choose_action(self, available_actions, state):\n",
    "        state = tuple(state.flatten())\n",
    "        if np.random.uniform(0, 1) < self.epsilon:\n",
    "            action = random.choice(available_actions)\n",
    "            return action\n",
    "        else:\n",
    "            qs = [self.getQ(state, action) for action in available_actions]\n",
    "            maxQ = max(qs)\n",
    "            if qs.count(maxQ) > 1:\n",
    "                best = [i for i in range(len(available_actions)) if qs[i] == maxQ]\n",
    "                i = random.choice(best)\n",
    "            else:\n",
    "                i = qs.index(maxQ)\n",
    "        \n",
    "        action = available_actions[i]\n",
    "        return action\n",
    "    \n",
    "    def getQ(self, state, action):\n",
    "        return self.Q.get((state, action), 0)\n",
    "    \n",
    "    def updateQ(self, state, new_state, reward, action, available_actions):\n",
    "        state = tuple(state.flatten())\n",
    "        new_state = tuple(new_state.flatten())\n",
    "        qs = []\n",
    "        for a in available_actions:\n",
    "            qs.append(self.getQ(new_state, a))\n",
    "        if qs:\n",
    "            max_next_Q = max(qs)\n",
    "        else:\n",
    "            max_next_Q = 0.0\n",
    "        #print(\"qs:\",qs)\n",
    "        #print(\"Q before:\", self.getQ(state, action))\n",
    "        self.Q[(state, action)] = ((1 - self.alpha) * self.getQ(state, action)) + (self.alpha * (reward + self.gamma * max_next_Q))\n",
    "        #print(\"Q after:\", self.getQ(state, action))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play(env, q_agent, r_agent, n_episodes, learn=False):\n",
    "    #print(\"running\")\n",
    "    \n",
    "    rewards = np.zeros(n_episodes)\n",
    "    \n",
    "    for episode in range(n_episodes):\n",
    "        env.reset(first_player='o')\n",
    "        reward = 0\n",
    "        game_over = False\n",
    "        \n",
    "        # Random agent moves first\n",
    "        state = np.copy(env.grid)\n",
    "        action = r_agent.choose_action(env.available_actions, state)\n",
    "        env.act(action)\n",
    "        env.change_turn()\n",
    "        state = np.copy(env.grid)\n",
    "        \n",
    "        while not game_over:\n",
    "            action = q_agent.choose_action(env.available_actions, state)\n",
    "            env.act(action)\n",
    "            new_state = np.copy(env.grid)\n",
    "            if env.was_winning_move():\n",
    "                game_over = True\n",
    "                reward = 1\n",
    "            elif env.grid_is_full():\n",
    "                game_over = True\n",
    "                reward = 0\n",
    "            else:\n",
    "                env.change_turn()\n",
    "                action_r = r_agent.choose_action(env.available_actions, state)\n",
    "                env.act(action_r)\n",
    "                new_state = np.copy(env.grid)\n",
    "                if env.was_winning_move():\n",
    "                    game_over = True\n",
    "                    reward = -1\n",
    "                elif env.grid_is_full():\n",
    "                    game_over = True\n",
    "                    reward = 0\n",
    "            if learn:\n",
    "                q_agent.updateQ(state, new_state, reward, action, env.available_actions)\n",
    "            state = np.copy(new_state)\n",
    "            env.change_turn()\n",
    "            \n",
    "        rewards[episode] = reward\n",
    "    return rewards\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running\n",
      "running\n",
      "running\n",
      "running\n",
      "running\n",
      "running\n",
      "running\n",
      "running\n",
      "running\n",
      "running\n",
      "running\n",
      "running\n",
      "running\n",
      "running\n",
      "running\n",
      "running\n",
      "running\n",
      "running\n",
      "running\n",
      "running\n",
      "running\n",
      "running\n",
      "running\n",
      "running\n",
      "running\n",
      "running\n",
      "running\n",
      "running\n",
      "running\n",
      "running\n",
      "complete\n"
     ]
    }
   ],
   "source": [
    "# Random agent\n",
    "n_agents = 30\n",
    "n_episodes = 5000\n",
    "all_rewards_random = np.zeros(n_episodes)\n",
    "\n",
    "for i in range(n_agents):\n",
    "    env = connect.Connect(verbose=False)\n",
    "    q_agent = RandomAgent()\n",
    "    r_agent = RandomAgent()\n",
    "\n",
    "    rewards = play(env, q_agent, r_agent, n_episodes, learn=False)\n",
    "    all_rewards_random += rewards\n",
    "\n",
    "print(\"complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "1431aa87b9e9019a4dbe6e696e0a9082",
     "grade": true,
     "grade_id": "cell-3ac2114f764e8410",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running\n",
      "running\n",
      "running\n",
      "running\n",
      "running\n",
      "running\n",
      "running\n",
      "running\n",
      "running\n",
      "running\n",
      "running\n",
      "running\n",
      "running\n",
      "running\n",
      "running\n",
      "running\n",
      "running\n",
      "running\n",
      "running\n",
      "running\n",
      "running\n",
      "running\n",
      "running\n",
      "running\n",
      "running\n",
      "running\n",
      "running\n",
      "running\n",
      "running\n",
      "running\n",
      "complete\n"
     ]
    }
   ],
   "source": [
    "### Write all your code for Part 1 within or above this cell. \n",
    "n_agents = 30\n",
    "n_episodes = 5000\n",
    "all_rewards_q_agent = np.zeros(n_episodes)\n",
    "\n",
    "for i in range(n_agents):\n",
    "    env = connect.Connect(verbose=False)\n",
    "    q_agent = QLearningAgent()\n",
    "    r_agent = RandomAgent()\n",
    "\n",
    "    rewards = play(env, q_agent, r_agent, n_episodes, learn=True)\n",
    "    all_rewards_q_agent += rewards\n",
    "\n",
    "print(\"complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113620240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Moving average function is not mine and was taken from the following link:\n",
    "# https://stackoverflow.com/questions/14313510/how-to-calculate-moving-average-using-numpy\n",
    "# Credit: Jaime\n",
    "def moving_average(a, n=100) :\n",
    "    ret = np.cumsum(a, dtype=float)\n",
    "    ret[n:] = ret[n:] - ret[:-n]\n",
    "    return ret[n - 1:] / n\n",
    "\n",
    "ma_q = moving_average(all_rewards_q_agent) / n_agents\n",
    "ma_r = moving_average(all_rewards_random) / n_agents\n",
    "\n",
    "plt.plot(ma_q, label=\"Q-learning Agent\")\n",
    "plt.plot(ma_r, label=\"Random Agent\")\n",
    "plt.title(\"Q-learning: Moving average return for \"+ str(n_agents) + \" agents\")\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Moving average (100) return\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "34a84d16a71c19e759cb0afc7b41bbbc",
     "grade": true,
     "grade_id": "cell-ce1405b859519f91",
     "locked": false,
     "points": 30,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "(A) [continued} Insert your static learning curve here (Plot 1).\n",
    "\n",
    "YOUR ANSWER HERE \n",
    "\n",
    "(B) In 3 sentences or less, explain your conclusions from the plot above. How close does your (average) agent get to the best possible level of performance? How efficiently does your (average) agent learn? \n",
    "\n",
    "YOUR ANSWER HERE \n",
    "\n",
    "(C) In five sentences or less, explain the key aspects of your implementation. How many state-action pairs do you represent in your Q-table? Describe and justify your settings of $\\alpha$ and $\\epsilon$. Are there any things you tried out that are not in your final implementation?\n",
    "\n",
    "YOUR ANSWER HERE\n",
    "\n",
    "(D) In the cell below, make it possible for us to produce from scratch a learning curve similar to Plot 1 but for a single agent, for a $k$ value of your own choosing. You do not need to include the baseline for random play.  This code should run in less than 30 seconds (ours runs in 2 seconds). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e65915a61d304027e4fbd2e714c4beba",
     "grade": true,
     "grade_id": "cell-e0e01e05236aee45",
     "locked": false,
     "points": 40,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### This cell should produce from scratch a plot showing a learning curve for a single agent.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2A\n",
    " \n",
    "Using the minimax policy you computed, answer the following question: The first player (Player 1) drops his/her first disk into column 2 (counting from the left). Consider the resulting state, shown in the following code cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = connect.Connect(verbose=False)\n",
    "env.reset(first_player='o')\n",
    "env.act(action=1)\n",
    "print(env.grid[::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the Minimax Value of this state for Player 2? That is, assuming an optimal opponent, does the Minimax Policy expect to win the game (value = 1), lose the game (value = –1), or end the game in a draw (value = 0)? Please state your answer as a number.    \n",
    "\n",
    "* The code cell below should compute this value and assign it to a variable called `state_value`.\n",
    "* Count the number of branches of the game tree that were examined and assign this number to a variable called `num_branches`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "7b00948d6cc98e71a2f9467263067bc0",
     "grade": false,
     "grade_id": "cell-9e3a2a1bebc09565",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### Write all your code for Part 2A in or above this cell.\n",
    "\n",
    "# state_value = ...\n",
    "# num_branches = ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0d9e96fd7c7ed9d9081eb564773f199c",
     "grade": true,
     "grade_id": "cell-c31d5222d21dd1d5",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# This is an autograded test cell. Do not delete or change, otherwise you will get \n",
    "# no marks for this part of the assignment. Please make sure that this cell has \n",
    "# access to the variables state_value and num_branches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2B\n",
    "Plot a learning curve similar to the one in Part 1, comparing your Q-learning algorithm, random play, and Minimax play. Assume as before that the opponent always plays first and uses a random policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "f6ed321958b16409ec1935b0fef7aa0d",
     "grade": true,
     "grade_id": "cell-a1d1652414bc7967",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### Write all your code for Exercise 2 (B) in or above this cell.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "614920eb9ba438cf5626dd59edc30252",
     "grade": true,
     "grade_id": "cell-1ea89dfffb81a041",
     "locked": false,
     "points": 10,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "Explain your findings in 3 or fewer sentences. Which policy is better? Why?\n",
    "\n",
    "YOUR ANSWER HERE.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3\n",
    "\n",
    "Using your algorithm, compute the value of the game for your player (recall: your player goes second against a random opponent). The code cell below should compute this value and assign it to a variable called `optimal_policy_value`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d7e4093f906a825959634f4ee6e6845f",
     "grade": false,
     "grade_id": "cell-a28f4f38b5cc6619",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### Write all your code for Part 3 in or above this cell.\n",
    "\n",
    "# optimal_policy_value = ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b3a945d86dc159320c257d69389cf765",
     "grade": true,
     "grade_id": "cell-1e0341a7a580c299",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# This is an autograded test cell. Do not delete or change, otherwise you will get \n",
    "# no marks for this part of the assignment. Please make sure that this cell has \n",
    "# access to the variable optimal_policy_value."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
